{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import types\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "from torch import optim\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "target_shape = [3,96,96]\n",
    "num_classes = 7\n",
    "num_layers = 5\n",
    "cut_size = 225\n",
    "init_lr = 0.0003\n",
    "batch_size = 128\n",
    "use_illumi_correct = False\n",
    "device= torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dir = ''\n",
    "\n",
    "train_data = torch.load(data_dir + 'pickles/AffectNet_train_full_p1.pt')\n",
    "train_img, train_y = train_data['images'], train_data['labels']\n",
    "\n",
    "test_data = torch.load(data_dir + 'pickles/AffectNet_test.pt')\n",
    "test_img, test_y = test_data['images'], test_data['emotion']\n",
    "\n",
    "all_perm = torch.tensor(np.load(data_dir+'permutations_1000.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nine_crops(image, size=[96,96], n_crop=3):\n",
    "    xx = yy = n_crop\n",
    "    x = size[0] // xx\n",
    "    y = size[1] // yy\n",
    "    crops = ()\n",
    "    for j in range(yy):\n",
    "        for i in range(xx):\n",
    "            left = i*x\n",
    "            up = y*j\n",
    "            right = left + x\n",
    "            low = up + y\n",
    "            region = image.crop((left,up,right,low))\n",
    "            region = transforms.RandomCrop(64)(region)\n",
    "            region = transforms.Resize((75, 75), Image.BILINEAR)(region)\n",
    "#             region = transforms.Lambda(rgb_jittering)(region)\n",
    "            crops += (region,)       \n",
    "    return crops\n",
    "\n",
    "\n",
    "# def rgb_jittering(im):\n",
    "#     im = np.array(im, 'int32')\n",
    "#     for ch in range(3):\n",
    "#         im[:, :, ch] += np.random.randint(-2, 2)\n",
    "#     im[im > 255] = 255\n",
    "#     im[im < 0] = 0\n",
    "#     return im.astype('uint8')\n",
    "\n",
    "\n",
    "class PuzzleCrop(object):\n",
    "    def __init__(self, size, n_crop):\n",
    "        self.size = size\n",
    "        self.n_crop = n_crop\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return nine_crops(img, self.size, self.n_crop)\n",
    "\n",
    "\n",
    "class Lambda(object):\n",
    "    def __init__(self, lambd):\n",
    "        assert isinstance(lambd, types.LambdaType)\n",
    "        self.lambd = lambd\n",
    "    def __call__(self, img):\n",
    "        return self.lambd(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "#======= data loaders =======#    \n",
    "n_crop = 3\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([int(cut_size*1.1),int(cut_size*1.1)]),\n",
    "    transforms.RandomCrop([cut_size,cut_size]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    PuzzleCrop([cut_size,cut_size],3),\n",
    "    Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    PuzzleCrop([cut_size,cut_size],3),\n",
    "    Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops]))\n",
    "])\n",
    "\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([cut_size,cut_size]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def default_loader(images):\n",
    "    img_tensor = train_transform(images)\n",
    "    return img_tensor\n",
    "\n",
    "def default_test_loader(images):\n",
    "    img_tensor = test_transform(images)\n",
    "    return img_tensor\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self,imgs,permutations,loader=default_loader):\n",
    "        self.images = imgs \n",
    "        self.permutations = permutations\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = self.images[index]\n",
    "        n_imgs = tmp = self.loader(img)\n",
    "        img = resize_transform(img)\n",
    "        label = torch.randint(0,1000,(1,))\n",
    "        for i in range(self.permutations.size(1)):\n",
    "            idx = self.permutations[label][0][i]\n",
    "            n_imgs[i] = tmp[idx]\n",
    "        return n_imgs,label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, lr=0.001,classes=1000):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        \n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        self.conv = alexnet.features\n",
    "        \n",
    "        self.fc6 = nn.Sequential()\n",
    "        self.fc6.add_module('fc6_s1',nn.Linear(256, 512))\n",
    "        self.fc6.add_module('relu6_s1',nn.ReLU(inplace=True))\n",
    "        self.fc6.add_module('drop6_s1',nn.Dropout(p=0.5))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4608,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096,classes)\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "#         self.optimizer=torch.optim.Adam([p for p in self.parameters() if p.requires_grad] , lr=lr)\n",
    "        self.optimizer=torch.optim.SGD(self.parameters(),lr=lr,momentum=0.9,weight_decay = 5e-4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,T,C,H,W = x.size()\n",
    "        x = x.transpose(0,1)\n",
    "        x_list = []\n",
    "        for i in range(9):\n",
    "            z = self.conv(x[i])\n",
    "            z = self.fc6(z.view(B,-1))\n",
    "            z = z.view([B,1,-1])\n",
    "            x_list.append(z)\n",
    "        x = torch.cat(x_list,1)\n",
    "        x = self.classifier(x.view(B,-1))\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, data_loader, num_epochs, lr=0.0001, min_loss=5.):\n",
    "        self.train()\n",
    "        start=time.time()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss=0\n",
    "            running_acc = 0.\n",
    "            total = 0\n",
    "            num_batches = 0\n",
    "            for count, (images, label) in enumerate(data_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                images=images.to(device)\n",
    "                label=torch.squeeze(label).to(device)\n",
    "\n",
    "                scores = self.forward(images)\n",
    "\n",
    "                loss =  self.loss_fn(scores, label) \n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.detach().item()\n",
    "\n",
    "                acc = (scores.argmax(-1) == label).float().sum()\n",
    "                running_acc += acc.item()\n",
    "\n",
    "                total+=images.size(0)\n",
    "                num_batches += 1\n",
    "            total_loss = running_loss/num_batches\n",
    "            if total_loss<min_loss:\n",
    "                min_loss = total_loss\n",
    "                torch.save(model.state_dict(),data_dir+'baselines/Jigsaw_AlexNet_AffectNet_minloss.pth')\n",
    "                print('save model', min_loss)\n",
    "            total_acc = running_acc/total\n",
    "            elapsed = time.time()-start\n",
    "            print('\\t', 'epoch=',epoch, '\\t time = {:.0f}m {:.0f}s'.format(elapsed // 60, elapsed % 60),'\\t lr=', lr,'\\t loss = ', total_loss , '\\t Acc = {:.6f}'.format(total_acc*100),'%')\n",
    "        return total_loss\n",
    "    \n",
    "    def test_model(self, data_loader):\n",
    "        self.eval()\n",
    "        start=time.time()\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_acc = 0\n",
    "        total = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        preds = []\n",
    "        truth = []\n",
    "        \n",
    "        for count, (images, label) in enumerate(data_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            images = images.to(device)\n",
    "\n",
    "            scores = self.forward(x).detach().cpu()\n",
    "\n",
    "            acc = (scores.argmax(-1) == label).float().sum()\n",
    "            running_acc += acc.item()\n",
    "            \n",
    "            total += images.size(0)\n",
    "\n",
    "            preds.extend(scores.argmax(-1).numpy())\n",
    "            truth.extend(label.numpy())\n",
    "            \n",
    "        total_acc = running_acc/total\n",
    "        elapsed = time.time()-start\n",
    "\n",
    "        print('testing','\\t time = {:.0f}m {:.0f}s'.format(elapsed // 60, elapsed % 60), '\\n Acc = {:.6f}'.format(total_acc*100),'%')\n",
    "        test_fscore = classification_report(truth, preds)\n",
    "        print(test_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc6): Sequential(\n",
      "    (fc6_s1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (relu6_s1): ReLU(inplace)\n",
      "    (drop6_s1): Dropout(p=0.5)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "Iteration 0\n",
      "save model 6.913087198909479\n",
      "\t epoch= 0 \t time = 3m 25s \t lr= 0.001 \t loss =  6.913087198909479 \t Acc = 0.120000 %\n",
      "save model 6.903112347514485\n",
      "\t epoch= 1 \t time = 6m 44s \t lr= 0.001 \t loss =  6.903112347514485 \t Acc = 0.150000 %\n",
      "save model 6.885312144367839\n",
      "\t epoch= 2 \t time = 10m 15s \t lr= 0.001 \t loss =  6.885312144367839 \t Acc = 0.232500 %\n",
      "save model 6.558815212676319\n",
      "\t epoch= 3 \t time = 13m 47s \t lr= 0.001 \t loss =  6.558815212676319 \t Acc = 1.427500 %\n",
      "save model 4.55873508118212\n",
      "\t epoch= 4 \t time = 17m 21s \t lr= 0.001 \t loss =  4.55873508118212 \t Acc = 11.845000 %\n",
      "save model 3.003993872255563\n",
      "\t epoch= 5 \t time = 20m 53s \t lr= 0.001 \t loss =  3.003993872255563 \t Acc = 31.620000 %\n",
      "save model 2.066050239264394\n",
      "\t epoch= 6 \t time = 24m 26s \t lr= 0.001 \t loss =  2.066050239264394 \t Acc = 49.392500 %\n",
      "save model 1.4971730303459656\n",
      "\t epoch= 7 \t time = 27m 58s \t lr= 0.001 \t loss =  1.4971730303459656 \t Acc = 62.910000 %\n",
      "save model 1.1622516899444044\n",
      "\t epoch= 8 \t time = 31m 30s \t lr= 0.001 \t loss =  1.1622516899444044 \t Acc = 70.885000 %\n",
      "save model 0.9314399961465464\n",
      "\t epoch= 9 \t time = 35m 2s \t lr= 0.001 \t loss =  0.9314399961465464 \t Acc = 76.792500 %\n",
      "save model 0.7735642262350637\n",
      "\t epoch= 10 \t time = 38m 34s \t lr= 0.001 \t loss =  0.7735642262350637 \t Acc = 80.822500 %\n",
      "save model 0.6794519435864287\n",
      "\t epoch= 11 \t time = 42m 7s \t lr= 0.001 \t loss =  0.6794519435864287 \t Acc = 83.187500 %\n",
      "save model 0.5739130625328698\n",
      "\t epoch= 12 \t time = 45m 40s \t lr= 0.001 \t loss =  0.5739130625328698 \t Acc = 85.627500 %\n",
      "save model 0.5137833267831193\n",
      "\t epoch= 13 \t time = 49m 12s \t lr= 0.001 \t loss =  0.5137833267831193 \t Acc = 87.240000 %\n",
      "save model 0.46162018008506334\n",
      "\t epoch= 14 \t time = 52m 44s \t lr= 0.001 \t loss =  0.46162018008506334 \t Acc = 88.765000 %\n",
      "save model 0.41852155351600706\n",
      "\t epoch= 15 \t time = 56m 15s \t lr= 0.001 \t loss =  0.41852155351600706 \t Acc = 89.735000 %\n",
      "save model 0.39445653060278574\n",
      "\t epoch= 16 \t time = 59m 48s \t lr= 0.001 \t loss =  0.39445653060278574 \t Acc = 90.272500 %\n",
      "save model 0.3630124096291515\n",
      "\t epoch= 17 \t time = 63m 20s \t lr= 0.001 \t loss =  0.3630124096291515 \t Acc = 91.017500 %\n",
      "save model 0.3341829152629017\n",
      "\t epoch= 18 \t time = 66m 52s \t lr= 0.001 \t loss =  0.3341829152629017 \t Acc = 91.815000 %\n",
      "save model 0.31311637753495775\n",
      "\t epoch= 19 \t time = 70m 23s \t lr= 0.001 \t loss =  0.31311637753495775 \t Acc = 92.362500 %\n",
      "save model 0.2928344724467768\n",
      "\t epoch= 20 \t time = 73m 55s \t lr= 0.001 \t loss =  0.2928344724467768 \t Acc = 92.702500 %\n",
      "save model 0.2809702751640314\n",
      "\t epoch= 21 \t time = 77m 25s \t lr= 0.001 \t loss =  0.2809702751640314 \t Acc = 93.167500 %\n",
      "save model 0.26695838015966905\n",
      "\t epoch= 22 \t time = 80m 49s \t lr= 0.001 \t loss =  0.26695838015966905 \t Acc = 93.485000 %\n",
      "save model 0.25434133710381324\n",
      "\t epoch= 23 \t time = 84m 19s \t lr= 0.001 \t loss =  0.25434133710381324 \t Acc = 93.792500 %\n",
      "save model 0.24251865926451577\n",
      "\t epoch= 24 \t time = 87m 53s \t lr= 0.001 \t loss =  0.24251865926451577 \t Acc = 93.932500 %\n",
      "save model 0.23660992919065701\n",
      "\t epoch= 25 \t time = 91m 27s \t lr= 0.001 \t loss =  0.23660992919065701 \t Acc = 94.250000 %\n",
      "save model 0.22211957568177781\n",
      "\t epoch= 26 \t time = 95m 7s \t lr= 0.001 \t loss =  0.22211957568177781 \t Acc = 94.532500 %\n",
      "\t epoch= 27 \t time = 98m 42s \t lr= 0.001 \t loss =  0.22257648353664258 \t Acc = 94.587500 %\n",
      "save model 0.21224127206415794\n",
      "\t epoch= 28 \t time = 102m 14s \t lr= 0.001 \t loss =  0.21224127206415794 \t Acc = 94.742500 %\n",
      "save model 0.2079952797426964\n",
      "\t epoch= 29 \t time = 105m 45s \t lr= 0.001 \t loss =  0.2079952797426964 \t Acc = 94.780000 %\n"
     ]
    }
   ],
   "source": [
    "train_input = Dataset(train_img,all_perm)\n",
    "train_loader = DataLoader(train_input, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_input = Dataset(test_img,all_perm)\n",
    "test_loader = DataLoader(test_input, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = Network(lr=0.001,classes=1000)\n",
    "model.to(device)\n",
    "print(model)\n",
    "LR=0.001\n",
    "loss = 10.\n",
    "for i in range(1):\n",
    "    print('Iteration', i)\n",
    "    loss = model.train_model(data_loader=train_loader, num_epochs=30,lr=LR, min_loss=loss)\n",
    "    LR = LR*0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
