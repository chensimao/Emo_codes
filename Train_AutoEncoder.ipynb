{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from utils import Conv2d\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "input_shape = [3,96,96]\n",
    "num_classes = 7\n",
    "num_layers = 5\n",
    "init_lr = 0.0003\n",
    "device = torch.device(\"cuda\")\n",
    "batch_size = 16\n",
    "use_fer=False\n",
    "use_illumi_correct = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def illumination_correction(img):\n",
    "    imhist,bins = np.histogram(img.flatten(),256,normed = True)\n",
    "    cdf = imhist.cumsum()\n",
    "    cdf = max(imhist) * cdf / cdf[-1]\n",
    "    im2 = np.interp(img.flatten(),bins[:-1],cdf)\n",
    "    im2 = im2.reshape(img.shape)\n",
    "    return torch.Tensor(im2/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_dir = ''\n",
    "\n",
    "if use_fer:\n",
    "    full_data = torch.load(data_dir + 'pickles/fer2013.pt')\n",
    "    full_img, full_emo = full_data['images'][:,None,:,:], full_data['label']\n",
    "\n",
    "    train_img,train_y = full_img[:28709],full_emo[:28709]\n",
    "    test_img,test_y = full_img[28709:28709+3589],full_emo[28709:28709+3589]\n",
    "\n",
    "    train_img = torch.cat((train_img,train_img,train_img),1)\n",
    "    test_img = torch.cat((test_img,test_img,test_img),1)\n",
    "\n",
    "else:\n",
    "#     train_data = torch.load(data_dir + 'pickles/AffectNet_train.pt')\n",
    "#     train_img, train_y = train_data['images'], train_data['emotion']\n",
    "    \n",
    "    train_data = torch.load(data_dir + 'pickles/AffectNet_train_full_p1.pt')\n",
    "    train_img, train_y = train_data['images'], train_data['labels']\n",
    "\n",
    "    test_data = torch.load(data_dir + 'pickles/AffectNet_test.pt')\n",
    "    test_img, test_y = test_data['images'], test_data['emotion']\n",
    "    \n",
    "if use_illumi_correct:\n",
    "    train_img = illumination_correction(train_img)\n",
    "    test_img = illumination_correction(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize([input_shape[1],input_shape[2]]), \n",
    "    transforms.RandomCrop([input_shape[1],input_shape[2]]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()#,\n",
    "#     normalize\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize([input_shape[1],input_shape[2]]),\n",
    "    transforms.CenterCrop([input_shape[1],input_shape[2]]),\n",
    "    transforms.ToTensor()#,\n",
    "#     normalize\n",
    "])\n",
    "\n",
    "def default_loader(images):\n",
    "    img_tensor = train_transform(images)\n",
    "    return img_tensor\n",
    "def default_test_loader(images):\n",
    "    img_tensor = test_transform(images)\n",
    "    return img_tensor\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, imgs,ys,loader=default_loader):\n",
    "        self.images = imgs \n",
    "        self.label = ys\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        fn = self.images[index]\n",
    "        img = self.loader(fn)\n",
    "        label = self.label[index]\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "class Train_AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, target_shape, init_lr, adam=True):\n",
    "        super(Train_AutoEncoder, self).__init__()\n",
    "        print('AutoEncoder_{}layers'.format(num_layers+1))\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.im_shape = target_shape\n",
    "        self.dec_im = None\n",
    "        self.imgs_train = None\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            # conv_0\n",
    "            Conv2d(in_channels=target_shape[0], out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            # conv_1\n",
    "            Conv2d(in_channels=32, out_channels=64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # conv_2\n",
    "            Conv2d(in_channels=64, out_channels=128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # conv_3\n",
    "            Conv2d(in_channels=128, out_channels=256, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # conv_4\n",
    "            Conv2d(in_channels=256, out_channels=512, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        if num_layers==5:\n",
    "            self.encoder_ = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(1024)\n",
    "            )\n",
    "            \n",
    "            self.decoder_ = nn.Sequential(\n",
    "                F.interpolate(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(512)\n",
    "            )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            # D2            \n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            Conv2d(in_channels=512, out_channels=256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            # D3\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            # D4\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            # D5\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            Conv2d(in_channels=32, out_channels=target_shape[0],kernel_size=3, stride=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "            \n",
    "            \n",
    "        self.optimizer = torch.optim.Adam(params=[p for p in self.parameters() if p.requires_grad], lr=init_lr, eps=1e-5)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    \n",
    "        if adam:\n",
    "            self.optimizer = torch.optim.Adam(params=[p for p in self.parameters() if p.requires_grad], lr=init_lr, eps=1e-5)\n",
    "        else:\n",
    "            self.optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "        self.loss_fn = nn.MSELoss() \n",
    "    \n",
    "    def forward(self, net, x):\n",
    "        batch_size = x.size(0)\n",
    "        for i in range(len(net)):\n",
    "            x = net[i](x)\n",
    "        return x\n",
    "        \n",
    "    def train_model(self, data_loader, num_epochs, init_lr, device):\n",
    "        self.train()\n",
    "        start=time.time()\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.\n",
    "            num_batches = 0\n",
    "            total_enc_im = []\n",
    "            total_dec_im = []\n",
    "            for count, (images, label) in enumerate(data_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                images = images.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                enc_im = self.forward(self.encoder, images)\n",
    "                dec_im = self.forward(self.decoder, enc_im)  \n",
    "                \n",
    "                loss = self.loss_fn(dec_im, images)\n",
    "                loss.backward()\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_enc_im.append(enc_im.detach().cpu())\n",
    "                total_dec_im.append(dec_im.detach().cpu())\n",
    "                \n",
    "                running_loss += loss.detach().cpu().item()\n",
    "                num_batches += 1\n",
    "            total_loss = running_loss/num_batches\n",
    "            elapsed = time.time()-start\n",
    "            print('\\t', 'epoch=',epoch+1, '\\t time = {:.0f}m {:.0f}s'.format(elapsed // 60, elapsed % 60), \n",
    "                  '\\t lr=', init_lr, '\\t loss = ', total_loss )\n",
    "            \n",
    "            total_dec_im = torch.cat(total_dec_im,0)\n",
    "            total_enc_im = torch.cat(total_enc_im,0)\n",
    "#         return total_enc_im, total_dec_im\n",
    "    \n",
    "    def test_model(self, data_loader, device):\n",
    "        self.eval()\n",
    "        start=time.time()\n",
    "        \n",
    "        preds = []\n",
    "        truth = []\n",
    "        total_enc_im = []\n",
    "        total_dec_im = []\n",
    "        for count, (images, label) in enumerate(data_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            images = images.to(device)\n",
    "\n",
    "            enc_im = self.forward(self.encoder, images)\n",
    "            dec_im = self.forward(self.decoder, enc_im)\n",
    "            \n",
    "            total_enc_im.append(enc_im.detach().cpu())\n",
    "            total_dec_im.append(dec_im.detach().cpu())\n",
    "\n",
    "        total_dec_im = torch.cat(total_dec_im,0)\n",
    "        total_enc_im = torch.cat(total_enc_im,0)\n",
    "        return total_enc_im, total_dec_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder_5layers\n",
      "\t epoch= 1 \t time = 0m 40s \t lr= 0.0003 \t loss =  0.08164751309833435\n",
      "\t epoch= 2 \t time = 1m 23s \t lr= 0.0003 \t loss =  0.012193172400366497\n",
      "\t epoch= 3 \t time = 2m 2s \t lr= 0.0003 \t loss =  0.009853484736304713\n",
      "\t epoch= 4 \t time = 2m 41s \t lr= 0.0003 \t loss =  0.00875028188991016\n",
      "\t epoch= 5 \t time = 3m 21s \t lr= 0.0003 \t loss =  0.00793762051513138\n",
      "\t epoch= 6 \t time = 4m 2s \t lr= 0.0003 \t loss =  0.007318517488754912\n",
      "\t epoch= 7 \t time = 4m 43s \t lr= 0.0003 \t loss =  0.006900601780050557\n",
      "\t epoch= 8 \t time = 5m 23s \t lr= 0.0003 \t loss =  0.006481693272976434\n",
      "\t epoch= 9 \t time = 6m 3s \t lr= 0.0003 \t loss =  0.006181856900130369\n",
      "\t epoch= 10 \t time = 6m 41s \t lr= 0.0003 \t loss =  0.005905172094430553\n",
      "\t epoch= 11 \t time = 7m 21s \t lr= 0.0003 \t loss =  0.005836370054496342\n",
      "\t epoch= 12 \t time = 7m 59s \t lr= 0.0003 \t loss =  0.00550121390558439\n",
      "\t epoch= 13 \t time = 8m 38s \t lr= 0.0003 \t loss =  0.005142930071146044\n",
      "\t epoch= 14 \t time = 9m 19s \t lr= 0.0003 \t loss =  0.004912875691581875\n",
      "\t epoch= 15 \t time = 10m 4s \t lr= 0.0003 \t loss =  0.0047181318875521286\n",
      "\t epoch= 16 \t time = 10m 45s \t lr= 0.0003 \t loss =  0.004543666711893596\n",
      "\t epoch= 17 \t time = 11m 26s \t lr= 0.0003 \t loss =  0.004398521303824366\n",
      "\t epoch= 18 \t time = 12m 7s \t lr= 0.0003 \t loss =  0.004311599563509566\n",
      "\t epoch= 19 \t time = 12m 47s \t lr= 0.0003 \t loss =  0.004418512627686539\n",
      "\t epoch= 20 \t time = 12m 57s \t lr= 0.0003 \t loss =  0.004511100473945544\n",
      "\t epoch= 21 \t time = 13m 7s \t lr= 0.0003 \t loss =  0.004312085857419255\n",
      "\t epoch= 22 \t time = 13m 16s \t lr= 0.0003 \t loss =  0.004193068733949163\n",
      "\t epoch= 23 \t time = 13m 26s \t lr= 0.0003 \t loss =  0.0039816395662401775\n",
      "\t epoch= 24 \t time = 13m 36s \t lr= 0.0003 \t loss =  0.0038903170492772233\n",
      "\t epoch= 25 \t time = 13m 46s \t lr= 0.0003 \t loss =  0.0038642185967687737\n",
      "\t epoch= 26 \t time = 13m 55s \t lr= 0.0003 \t loss =  0.0038468537046297637\n",
      "\t epoch= 27 \t time = 14m 5s \t lr= 0.0003 \t loss =  0.0037697987954162025\n",
      "\t epoch= 28 \t time = 14m 15s \t lr= 0.0003 \t loss =  0.003782093899162937\n",
      "\t epoch= 29 \t time = 14m 25s \t lr= 0.0003 \t loss =  0.003703837023546162\n",
      "\t epoch= 30 \t time = 14m 35s \t lr= 0.0003 \t loss =  0.0036750093685063326\n",
      "\t epoch= 31 \t time = 14m 44s \t lr= 0.0003 \t loss =  0.003628191948532378\n",
      "\t epoch= 32 \t time = 14m 54s \t lr= 0.0003 \t loss =  0.0036320696429659924\n",
      "\t epoch= 33 \t time = 15m 4s \t lr= 0.0003 \t loss =  0.0036117678187090104\n",
      "\t epoch= 34 \t time = 15m 14s \t lr= 0.0003 \t loss =  0.00365677840803584\n",
      "\t epoch= 35 \t time = 15m 23s \t lr= 0.0003 \t loss =  0.003541707086746823\n",
      "\t epoch= 36 \t time = 15m 33s \t lr= 0.0003 \t loss =  0.0034066134581095687\n",
      "\t epoch= 37 \t time = 15m 43s \t lr= 0.0003 \t loss =  0.003348117671932464\n",
      "\t epoch= 38 \t time = 15m 53s \t lr= 0.0003 \t loss =  0.0035105643668488415\n",
      "\t epoch= 39 \t time = 16m 3s \t lr= 0.0003 \t loss =  0.003149541084267641\n",
      "\t epoch= 40 \t time = 16m 13s \t lr= 0.0003 \t loss =  0.003012593370994136\n",
      "\t epoch= 41 \t time = 16m 23s \t lr= 0.0003 \t loss =  0.002997567758100218\n",
      "\t epoch= 42 \t time = 16m 32s \t lr= 0.0003 \t loss =  0.002961235272923493\n",
      "\t epoch= 43 \t time = 16m 43s \t lr= 0.0003 \t loss =  0.002956703095803182\n",
      "\t epoch= 44 \t time = 16m 52s \t lr= 0.0003 \t loss =  0.0030065820367419964\n",
      "\t epoch= 45 \t time = 17m 2s \t lr= 0.0003 \t loss =  0.003032992819332641\n",
      "\t epoch= 46 \t time = 17m 12s \t lr= 0.0003 \t loss =  0.0030838155812800746\n",
      "\t epoch= 47 \t time = 17m 22s \t lr= 0.0003 \t loss =  0.0030019429956720163\n",
      "\t epoch= 48 \t time = 17m 31s \t lr= 0.0003 \t loss =  0.0029804978326184155\n",
      "\t epoch= 49 \t time = 17m 41s \t lr= 0.0003 \t loss =  0.0030020104963587573\n",
      "\t epoch= 50 \t time = 17m 51s \t lr= 0.0003 \t loss =  0.003034011859523311\n",
      "\t epoch= 51 \t time = 18m 1s \t lr= 0.0003 \t loss =  0.0030374626382402904\n",
      "\t epoch= 52 \t time = 18m 11s \t lr= 0.0003 \t loss =  0.0030900258049964225\n",
      "\t epoch= 53 \t time = 18m 21s \t lr= 0.0003 \t loss =  0.002927438205014489\n",
      "\t epoch= 54 \t time = 18m 31s \t lr= 0.0003 \t loss =  0.002808111280704674\n",
      "\t epoch= 55 \t time = 18m 40s \t lr= 0.0003 \t loss =  0.0027644637058867505\n",
      "\t epoch= 56 \t time = 18m 50s \t lr= 0.0003 \t loss =  0.0028195931622971137\n",
      "\t epoch= 57 \t time = 19m 0s \t lr= 0.0003 \t loss =  0.0027429564785824653\n",
      "\t epoch= 58 \t time = 19m 10s \t lr= 0.0003 \t loss =  0.0026962150974820056\n",
      "\t epoch= 59 \t time = 19m 20s \t lr= 0.0003 \t loss =  0.0026593822039680803\n",
      "\t epoch= 60 \t time = 19m 30s \t lr= 0.0003 \t loss =  0.002704574567048925\n",
      "\t epoch= 61 \t time = 19m 40s \t lr= 0.0003 \t loss =  0.0026081484390558787\n",
      "\t epoch= 62 \t time = 19m 50s \t lr= 0.0003 \t loss =  0.002579494268361258\n",
      "\t epoch= 63 \t time = 19m 60s \t lr= 0.0003 \t loss =  0.002565316913317736\n",
      "\t epoch= 64 \t time = 20m 10s \t lr= 0.0003 \t loss =  0.0025473924717317295\n",
      "\t epoch= 65 \t time = 20m 20s \t lr= 0.0003 \t loss =  0.0024926495524633624\n",
      "\t epoch= 66 \t time = 20m 30s \t lr= 0.0003 \t loss =  0.002466159460207099\n",
      "\t epoch= 67 \t time = 20m 39s \t lr= 0.0003 \t loss =  0.0024753645525981576\n",
      "\t epoch= 68 \t time = 20m 49s \t lr= 0.0003 \t loss =  0.002579936494553232\n",
      "\t epoch= 69 \t time = 20m 59s \t lr= 0.0003 \t loss =  0.002458930648140371\n",
      "\t epoch= 70 \t time = 21m 9s \t lr= 0.0003 \t loss =  0.002382565340767168\n",
      "\t epoch= 71 \t time = 21m 19s \t lr= 0.0003 \t loss =  0.002371441401736853\n",
      "\t epoch= 72 \t time = 21m 29s \t lr= 0.0003 \t loss =  0.0023131641409398144\n",
      "\t epoch= 73 \t time = 21m 38s \t lr= 0.0003 \t loss =  0.002216533453684283\n",
      "\t epoch= 74 \t time = 21m 48s \t lr= 0.0003 \t loss =  0.0021637856240541626\n",
      "\t epoch= 75 \t time = 21m 58s \t lr= 0.0003 \t loss =  0.002158639996661273\n",
      "\t epoch= 76 \t time = 22m 8s \t lr= 0.0003 \t loss =  0.0021821450273034303\n",
      "\t epoch= 77 \t time = 22m 18s \t lr= 0.0003 \t loss =  0.0022447743404180355\n",
      "\t epoch= 78 \t time = 22m 27s \t lr= 0.0003 \t loss =  0.0022621478919433134\n",
      "\t epoch= 79 \t time = 22m 37s \t lr= 0.0003 \t loss =  0.0022417955657628844\n",
      "\t epoch= 80 \t time = 22m 47s \t lr= 0.0003 \t loss =  0.002269123671321224\n",
      "\t epoch= 81 \t time = 22m 57s \t lr= 0.0003 \t loss =  0.00218044784925793\n",
      "\t epoch= 82 \t time = 23m 7s \t lr= 0.0003 \t loss =  0.0021407968570907776\n",
      "\t epoch= 83 \t time = 23m 17s \t lr= 0.0003 \t loss =  0.0021027092179751287\n",
      "\t epoch= 84 \t time = 23m 26s \t lr= 0.0003 \t loss =  0.0020962841675901726\n",
      "\t epoch= 85 \t time = 23m 36s \t lr= 0.0003 \t loss =  0.002109581668920747\n",
      "\t epoch= 86 \t time = 23m 46s \t lr= 0.0003 \t loss =  0.0020856467462633844\n",
      "\t epoch= 87 \t time = 23m 56s \t lr= 0.0003 \t loss =  0.0020692065383677615\n",
      "\t epoch= 88 \t time = 24m 6s \t lr= 0.0003 \t loss =  0.0020860928455240105\n",
      "\t epoch= 89 \t time = 24m 16s \t lr= 0.0003 \t loss =  0.00210921646501937\n",
      "\t epoch= 90 \t time = 24m 26s \t lr= 0.0003 \t loss =  0.002077526646266483\n",
      "\t epoch= 91 \t time = 24m 36s \t lr= 0.0003 \t loss =  0.002111939950973714\n",
      "\t epoch= 92 \t time = 24m 45s \t lr= 0.0003 \t loss =  0.00210488816249061\n",
      "\t epoch= 93 \t time = 24m 55s \t lr= 0.0003 \t loss =  0.002124968578094897\n",
      "\t epoch= 94 \t time = 25m 5s \t lr= 0.0003 \t loss =  0.002065027899695688\n",
      "\t epoch= 95 \t time = 25m 15s \t lr= 0.0003 \t loss =  0.0021020268934213273\n",
      "\t epoch= 96 \t time = 25m 24s \t lr= 0.0003 \t loss =  0.002240486932624999\n",
      "\t epoch= 97 \t time = 25m 34s \t lr= 0.0003 \t loss =  0.0021804385966319403\n",
      "\t epoch= 98 \t time = 25m 44s \t lr= 0.0003 \t loss =  0.0021255990616832624\n",
      "\t epoch= 99 \t time = 25m 54s \t lr= 0.0003 \t loss =  0.002112332329613297\n",
      "\t epoch= 100 \t time = 26m 4s \t lr= 0.0003 \t loss =  0.0021027136497310103\n"
     ]
    }
   ],
   "source": [
    "train_input  = Dataset(train_img,train_y)\n",
    "train_loader = DataLoader(train_input, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_input  = Dataset(test_img,test_y,loader=default_test_loader)\n",
    "test_loader = DataLoader(test_input, batch_size=batch_size,shuffle=False)\n",
    "\n",
    "model = Train_AutoEncoder(num_layers=4, target_shape=input_shape, init_lr=init_lr)\n",
    "model.to(device)\n",
    "model.train_model(data_loader=test_loader, num_epochs=100, init_lr=init_lr, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),data_dir+'BaselinesGray/AutoEncoder_AffectNet_inputsize{}_epo100.pth'.format(96))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
